{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 30000 line start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING FROM RUSSIAN TO POLISH\n",
    "# russian_data=pd.read_csv(\"data/ru/ru.txt\",sep='\\n',header=None)\n",
    "# polish_data=pd.read_csv(\"data/pl/pl.txt\",sep='\\n',header=None)\n",
    "# df = pd.DataFrame(columns=['ru','pl'])\n",
    "\n",
    "# FOR TRAINING FROM POLISH TO RUSSIAN\n",
    "russian_data=pd.read_csv(\"data/pl/pl.txt\",sep='\\n',header=None)\n",
    "polish_data=pd.read_csv(\"data/ru/ru.txt\",sep='\\n',header=None)\n",
    "df = pd.DataFrame(columns=['pl','ru'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(polish_data)):\n",
    "        df.loc[a] = russian_data[0][a].split(\" \"),polish_data[0][a].split(\" \")\n",
    "\n",
    "del polish_data\n",
    "del russian_data\n",
    "\n",
    "pl_ru_pair = df.to_numpy()\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dutch and english vocabularies\n",
    "def vocab(eng_ru_pair):\n",
    "    russian_words = []\n",
    "    polish_words = []\n",
    "\n",
    "    for s_p in pl_ru_pair:\n",
    "        for ew in s_p[1]: \n",
    "            polish_words.append(ew)\n",
    "        for fw in s_p[0]: \n",
    "            russian_words.append(fw)\n",
    "\n",
    "    polish_words = sorted(list(set(polish_words)), key=lambda s: s.lower()) \n",
    "    russian_words = sorted(list(set(russian_words)), key=lambda s: s.lower())\n",
    "    # print('Polish vocab: ', polish_words)\n",
    "    # print('Russian vocab: ', russian_words)\n",
    "    return polish_words,russian_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size of the english and dutch words\n",
    "def vocab_size(polish_words,russian_words):\n",
    "    polish_vocab_size = len(polish_words)\n",
    "    russian_vocab_size = len(russian_words)\n",
    "    print('polish_vocab_size: ', polish_vocab_size)\n",
    "    print('russian_vocab_size: ', russian_vocab_size)\n",
    "    return polish_vocab_size,russian_vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "polish_vocab_size:  44658\nrussian_vocab_size:  42745\n"
    }
   ],
   "source": [
    "# Routine to uniformly initialize word translation probabilities in t hash\n",
    "def init_prob(t, prev, init_val, pl_ru_pair):\n",
    "    for a in range(len(pl_ru_pair)):\n",
    "        for r_word in pl_ru_pair[a][0]:\n",
    "            for e_word in pl_ru_pair[a][1]:\n",
    "                t[(e_word, r_word)] = init_val\n",
    "                prev[(e_word, r_word)] = 0\n",
    "\n",
    "\n",
    "# Main routine\n",
    "polish_words,russian_words = vocab(pl_ru_pair)\n",
    "polish_vocab_size,russian_vocab_size = vocab_size(polish_words,russian_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "No. of russian/polish pairs:  5214497\n0.9999766054509299\n0.9999766054509299\n0.4064055753304225\n0.23125982570232062\n0.15868122901803722\n0.12121628583901017\n0.11177520065951979\n0.08614411332725525\n0.07692220376620923\n0.061989161358031675\n0.05475398356657965\n0.04685599086376124\n0.03872216104896753\n0.03339846924834716\n0.038777908447023335\n0.03583602943918601\n0.0377968787324796\n0.041576715832799954\n0.03992868640570271\n0.03467322273967452\n0.028424743211989928\n0.022800575851583793\n0.01830600484398065\nnumber_of_epochs 23\nNo. of russian/polish pairs: 5214497\nTime taken to train the model 00:34:54\n"
    }
   ],
   "source": [
    "# Initialize probabilities uniformly\n",
    "final_total = {}\n",
    "t = {}\n",
    "prev = {}\n",
    "init_val = 1.0 / russian_vocab_size\n",
    "init_prob(t, prev, init_val, pl_ru_pair)\n",
    "\n",
    "print('No. of russian/polish pairs: ', len(t))\n",
    "\n",
    "\n",
    "delta = 1 \n",
    "epsilon = 0.02\n",
    "\n",
    "number_of_epochs = 0\n",
    "# Loop while not converged\n",
    "while (delta > epsilon):\n",
    "\n",
    "    # Initialize\n",
    "    count = {}\n",
    "    total = {}\n",
    "    pair_delta = 0\n",
    "    \n",
    "    for sp in pl_ru_pair:\n",
    "        for fw in sp[0]:\n",
    "            total[fw] = 0.0\n",
    "            for ew in sp[1]:\n",
    "                count[(ew,fw)] = 0.0\n",
    "        \n",
    "    for sp in pl_ru_pair:\n",
    "\n",
    "        # Compute normalization\n",
    "        for ew in sp[1]:\n",
    "            final_total[ew] = 0.0\n",
    "            for fw in sp[0]:\n",
    "                final_total[ew] += t[(ew, fw)]\n",
    "\n",
    "        # Collect counts\n",
    "        for ew in sp[1]:\n",
    "            for fw in sp[0]:\n",
    "                count[(ew, fw)] += t[(ew, fw)] / final_total[ew]\n",
    "                total[fw] += t[(ew, fw)] / final_total[ew]\n",
    "\n",
    "                \n",
    "    for a in range(len(pl_ru_pair)):\n",
    "        for e_word in pl_ru_pair[a][1]:\n",
    "            for r_word in pl_ru_pair[a][0]:\n",
    "                pair_delta = max(pair_delta, abs(prev[(e_word, r_word)]-t[(e_word, r_word)]))\n",
    "                prev[(e_word, r_word)] = t[(e_word, r_word)]\n",
    "                t[(e_word, r_word)] = count[(e_word, r_word)] / total[r_word]\n",
    "                \n",
    "    \n",
    "    number_of_epochs +=1\n",
    "    delta = pair_delta\n",
    "    print(delta)\n",
    "    if(number_of_epochs>50):\n",
    "        break\n",
    "\n",
    "print(\"number_of_epochs\",number_of_epochs)\n",
    "\n",
    "#Finding the maximum matrix\n",
    "print(\"No. of russian/polish pairs:\",len(t))\n",
    "\n",
    "convert = {}\n",
    "coverted_prob = {}\n",
    "\n",
    "for p_ed in t.keys():\n",
    "    if p_ed[1] not in coverted_prob.keys():\n",
    "        coverted_prob[p_ed[1]] = 0\n",
    "    if(coverted_prob[p_ed[1]] < t[p_ed]):\n",
    "        coverted_prob[p_ed[1]] = t[p_ed]\n",
    "        convert[p_ed[1]] = p_ed[0]\n",
    "\n",
    "np.save('pl_to_ru_20k.npy',convert)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Time taken to train the model\",time.strftime('%H:%M:%S', time.gmtime(t1-t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}